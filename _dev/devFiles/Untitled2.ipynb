{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroinfl(endog, exog_count, exog_zero, dist = 'poisson', link = 'logit', weights = None, offsetx = None,\\\n",
    "             offsetz = None, method = 'L-BFGS-B', start = None, EM = True, \\\n",
    "                                        tol = None, options = None, factr = 1.0):\n",
    "    ## Function starts\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import statsmodels.api as sm\n",
    "    import scipy as sp\n",
    "    import scipy.stats as st\n",
    "    import sys\n",
    "    import warnings\n",
    "\n",
    "    FLOAT_EPS = np.finfo(float).eps\n",
    "    \n",
    "    Y = endog\n",
    "    X = exog_count\n",
    "    Z = exog_zero\n",
    "    ## convenience variables\n",
    "    Y = np.squeeze(y.values)\n",
    "    n = len(Y)\n",
    "    kx = X.shape[1] # Number of columns in X\n",
    "    kz = Z.shape[1]\n",
    "    Y0 = Y <= 0\n",
    "    Y1 = Y > 0\n",
    "    \n",
    "    ## sanity checks\n",
    "    if len(Y) < 1:\n",
    "        sys.exit(\"empty model\")\n",
    "    if np.all(Y > 0):\n",
    "        sys.exit(\"invalid dependent variable, minimum count is not zero\")  \n",
    "    if np.array_equal(np.asarray(Y), (np.round(Y + 0.001)).astype(int)) is False:\n",
    "        sys.exit(\"invalid dependent variable, non-integer values\")\n",
    "    Y = (np.round(Y + 0.001)).astype(int)\n",
    "    if np.any(Y < 0):\n",
    "        sys.exit(\"invalid dependent variable, negative counts\")\n",
    "\n",
    "    ## weights and offset\n",
    "\n",
    "    if weights is None:\n",
    "        weights = 1.0\n",
    "    weights = np.ndarray.flatten(np.array(weights))\n",
    "    if weights.size == 1:\n",
    "        weights = np.repeat(weights,n)\n",
    "    weights = pd.Series(data = weights, index = X.index)\n",
    "\n",
    "    if offsetx is None:\n",
    "        offsetx = 0.0\n",
    "    offsetx = np.ndarray.flatten(np.array(offsetx))\n",
    "    if offsetx.size == 1:\n",
    "        offsetx = np.repeat(offsetx,n)\n",
    "\n",
    "    if offsetz is None:\n",
    "        offsetz = 0.0\n",
    "    offsetz = np.ndarray.flatten(np.array(offsetz))\n",
    "    if offsetz.size == 1:\n",
    "        offsetz = np.repeat(offsetz,n)\n",
    "        \n",
    "    class Logit(object):\n",
    "        def __init__(self):\n",
    "            self.linkclass = sm.genmod.families.links.logit\n",
    "        def link(self, mu):\n",
    "            return mu/(1.0 + mu)\n",
    "        def link_inv(self, eta):\n",
    "            thresh = 30.0\n",
    "            eta = np.minimum(np.maximum(eta,-thresh), thresh)\n",
    "            exp_eta = np.exp(eta)\n",
    "            return exp_eta/(1+exp_eta)\n",
    "        def link_inv_deriv(self, eta):\n",
    "            thresh = 30.0\n",
    "            eta[abs(eta) > thresh] = FLOAT_EPS\n",
    "            return np.exp(eta)/(1+np.exp(eta))**2\n",
    "\n",
    "    class Probit(object):\n",
    "        def __init__(self):\n",
    "            self.linkclass = sm.genmod.families.links.probit\n",
    "        def link(self, mu):\n",
    "            return st.norm.ppf(mu)\n",
    "        def link_inv(self, eta):\n",
    "            thresh = -st.norm.ppf(FLOAT_EPS)\n",
    "            eta = np.minimum(np.maximum(eta,-thresh),thresh)\n",
    "            return st.norm.cdf(eta)\n",
    "        def link_inv_deriv(self, eta):\n",
    "            return np.maximum(st.norm.pdf(eta),FLOAT_EPS)\n",
    "    \n",
    "    class CLogLog(object):\n",
    "        def __init__(self):\n",
    "            self.linkclass = sm.genmod.families.links.cloglog\n",
    "        def link(self, mu):\n",
    "            return np.log(-np.log(1 - mu))\n",
    "        def link_inv(self, eta):\n",
    "            return np.maximum(np.minimum(-np.expm1(-np.exp(eta)),1-FLOAT_EPS),FLOAT_EPS)\n",
    "        def link_inv_deriv(self, eta):\n",
    "            eta = np.minimum(eta,700)\n",
    "            return np.maximum(np.exp(eta)*np.exp(-np.exp(eta)),FLOAT_EPS)\n",
    "    \n",
    "    class Cauchit(object):\n",
    "        def __init__(self):\n",
    "            self.linkclass = sm.genmod.families.links.cauchy\n",
    "        def link(self, mu):\n",
    "            return st.cauchy.ppf(mu)\n",
    "        def link_inv(self, eta):\n",
    "            thresh = -st.cauchy.ppf(FLOAT_EPS)\n",
    "            eta = np.minimum(np.maximum(eta,-thresh),thresh)\n",
    "            return st.cauchy.cdf(eta)\n",
    "        def link_inv_deriv(self, eta):\n",
    "            return nnp.maximum(st.cauchy.pdf(eta),FLOAT_EPS)\n",
    "    \n",
    "    class Log(object):\n",
    "        def __init__(self):\n",
    "            self.linkclass = sm.genmod.families.links.log\n",
    "        def link(self, mu):\n",
    "            return np.log(mu)\n",
    "        def link_inv(self, eta):\n",
    "            return np.maximum(np.exp(eta), FLOAT_EPS)\n",
    "        def link_inv_deriv(self, eta):\n",
    "            return np.maximum(np.exp(eta), FLOAT_EPS)\n",
    "        \n",
    "    def setLinkClass(argument):\n",
    "        Link = {\n",
    "            'logit': Logit(),\n",
    "            'probit': Probit(),\n",
    "            'cloglog': CLogLog(),\n",
    "            'cauchit': Cauchit(),\n",
    "            'log': Log(),\n",
    "        }\n",
    "        return Link.get(argument, Logit())\n",
    "    \n",
    "    ## binary link processing\n",
    "    linkstr = link\n",
    "    linkobj = setLinkClass(linkstr)\n",
    "    linkList = ['logit','probit','cauchit','cloglog','log']\n",
    "    if linkstr not in linkList:\n",
    "        warnings.warn(linkstr +\" link not valid. Available links are: \" + str(linkList))\n",
    "        linkstr = 'logit'\n",
    "\n",
    "    def ziPoisson(parms, sign = 1.0):\n",
    "        \"\"\"\n",
    "        Log-likelihood of Zero Inflated Poisson.\n",
    "        \"\"\"\n",
    "        ## count mean\n",
    "        mu = np.exp(np.dot(X,parms[np.arange(kx)]) + offsetx)\n",
    "        ## binary mean\n",
    "        phi = linkobj.link_inv(np.dot(Z, parms[np.arange(kx,kx+kz)]) + offsetz)\n",
    "        ## log-likelihood for y = 0 and y >= 1\n",
    "        loglik0 = np.log(phi + np.exp(np.log(1-phi) - mu)) \n",
    "        loglik1 = np.log(1-phi) + sp.stats.poisson.logpmf(Y, mu)\n",
    "        ## collect and return\n",
    "        loglik = np.dot(weights[Y0],loglik0[Y0])+np.dot(weights[Y1],loglik1[Y1])\n",
    "        return sign*loglik\n",
    "\n",
    "    def gradPoisson(parms, sign = 1.0):\n",
    "        \"\"\"\n",
    "        Gradient of Zero Inflated Poisson Log-likelihood.\n",
    "        \"\"\"\n",
    "        ## count mean\n",
    "        eta = np.dot(X,parms[np.arange(kx)]) + offsetx\n",
    "        mu = np.exp(eta)\n",
    "        ## binary mean\n",
    "        etaz = np.dot(Z, parms[np.arange(kx,kx+kz)]) + offsetz\n",
    "        muz = linkobj.link_inv(etaz)\n",
    "        ## densities at 0\n",
    "        clogdens0 = -mu\n",
    "        dens0 = muz*(1-Y1.astype(float)) + np.exp(np.log(1 - muz) + clogdens0)\n",
    "        ## working residuals  \n",
    "        wres_count = np.where(Y1,Y-mu,-np.exp(-np.log(dens0) + \n",
    "                                          np.log(1 - muz) + clogdens0 + np.log(mu))) \n",
    "        link_etaz = linkobj.link_inv_deriv(etaz)\n",
    "        wres_zero  = np.where(Y1,-1/(1-muz) * link_etaz, \\\n",
    "                          (link_etaz - np.exp(clogdens0) * link_etaz)/dens0)   \n",
    "    \n",
    "        return sign*(np.hstack((np.expand_dims(wres_count*weights,axis=1)*X, \\\n",
    "                np.expand_dims(wres_zero*weights,axis=1)*Z))).sum(axis=0)\n",
    "    \n",
    "    def convert_params(mu, theta):\n",
    "        \"\"\"\n",
    "        Convert mean/dispersion parameterization of a negative binomial to the ones scipy supports\n",
    "\n",
    "        \"\"\"\n",
    "        r = theta\n",
    "        var = mu + 1 / r * mu ** 2\n",
    "        p = (var - mu) / var\n",
    "        return r, 1 - p\n",
    "    \n",
    "    def ziNegBin(parms, sign = 1.0):\n",
    "        \"\"\"\n",
    "        Log-Likelihood of Zero Inflated Negative Binomial.\n",
    "        \"\"\"\n",
    "        ## count mean\n",
    "        mu = np.exp(np.dot(X,parms[np.arange(kx)]) + offsetx)\n",
    "        ## binary mean\n",
    "        phi = linkobj.link_inv(np.dot(Z, parms[np.arange(kx,kx+kz)]) + offsetz)\n",
    "        ## negbin size\n",
    "        theta = np.exp(parms[kx+kz])\n",
    "    \n",
    "        ## log-likelihood for y = 0 and y >= 1 sp.stats.poisson.logpmf(Y, mu)\n",
    "        loglik0 = np.log(phi + np.exp(np.log(1-phi) + \\\n",
    "                                   st.nbinom.logpmf(0,*convert_params(theta = theta, mu = mu)) ) )\n",
    "        loglik1 = np.log(1-phi) + st.nbinom.logpmf(Y,*convert_params(theta = theta, mu = mu))\n",
    "\n",
    "        ## collect and return\n",
    "        loglik = np.dot(weights[Y0],loglik0[Y0])+np.dot(weights[Y1],loglik1[Y1])\n",
    "        return sign*loglik\n",
    "  \n",
    "    def ziGeom(parms, sign = 1.0):\n",
    "        return ziNegBin(np.hstack((parms, 0)), sign)\n",
    "    \n",
    "    def gradGeom(parms, sign = 1.0):\n",
    "        \"\"\"\n",
    "        Gradient of Zero Inflated Geometric Log-likelihood.\n",
    "        \n",
    "        \"\"\"\n",
    "        ## count mean\n",
    "        eta = np.dot(X,parms[np.arange(kx)]) + offsetx\n",
    "        mu = np.exp(eta)\n",
    "        ## binary mean\n",
    "        etaz = np.dot(Z, parms[np.arange(kx,kx+kz)]) + offsetz\n",
    "        muz = linkobj.link_inv(etaz) \n",
    "\n",
    "        ## densities at 0\n",
    "        clogdens0 = st.nbinom.logpmf(0,*convert_params(theta = 1, mu = mu))\n",
    "        dens0 = muz*(1-Y1.astype(float)) + np.exp(np.log(1 - muz) + clogdens0)\n",
    "\n",
    "        ## working residuals  \n",
    "        wres_count = np.where(Y1,Y - mu*(Y + 1)/(mu + 1), \\\n",
    "                              -np.exp(-np.log(dens0) + np.log(1 - muz) + clogdens0 +\\\n",
    "                                      -np.log(mu+1) + np.log(mu))) \n",
    "        link_etaz = linkobj.link_inv_deriv(etaz)\n",
    "        wres_zero  = np.where(Y1,-1/(1-muz) * link_etaz, \\\n",
    "                          (link_etaz - np.exp(clogdens0) * link_etaz)/dens0)\n",
    "      \n",
    "        return sign*(np.hstack((np.expand_dims(wres_count*weights,axis=1)*X, \\\n",
    "                np.expand_dims(wres_zero*weights,axis=1)*Z))).sum(axis=0)\n",
    "    \n",
    "    def gradNegBin(parms, sign = 1.0): \n",
    "        \"\"\"\n",
    "        Gradient of Zero Inflated Negative Binomial Log-likelihood. \n",
    "        (Negetive Binomial2 to be specific.)\n",
    "        \n",
    "        \"\"\"\n",
    "        ## count mean\n",
    "        eta = np.dot(X,parms[np.arange(kx)]) + offsetx\n",
    "        mu = np.exp(eta)\n",
    "        ## binary mean\n",
    "        etaz = np.dot(Z, parms[np.arange(kx,kx+kz)]) + offsetz\n",
    "        muz = linkobj.link_inv(etaz)    \n",
    "        ## negbin size\n",
    "        theta = np.exp(parms[kx+kz])\n",
    "\n",
    "        ## densities at 0\n",
    "        clogdens0 = st.nbinom.logpmf(0,*convert_params(theta = theta, mu = mu))\n",
    "        dens0 = muz*(1-Y1.astype(float)) + np.exp(np.log(1 - muz) + clogdens0)\n",
    "        \n",
    "        ## working residuals  \n",
    "        wres_count = np.where(Y1,Y - mu*(Y + theta)/(mu + theta), \\\n",
    "                              -np.exp(-np.log(dens0) + np.log(1 - muz) + clogdens0 + np.log(theta) +\\\n",
    "                                      -np.log(mu+theta) + np.log(mu))) \n",
    "        link_etaz = linkobj.link_inv_deriv(etaz)\n",
    "        wres_zero  = np.where(Y1,-1/(1-muz) * link_etaz, \\\n",
    "                          (link_etaz - np.exp(clogdens0) * link_etaz)/dens0)\n",
    "        \n",
    "        wres_theta = theta*np.where(Y1, sp.special.digamma(Y + theta) - sp.special.digamma(theta) +\\\n",
    "                                   np.log(theta) - np.log(mu + theta) + 1 - (Y + theta)/(mu + theta),\\\n",
    "                                   np.exp(-np.log(dens0) + np.log(1 - muz) + clogdens0)*\\\n",
    "                                   (np.log(theta) - np.log(mu + theta) + 1 - theta/(mu+theta) ) )\n",
    "        \n",
    "        return sign*(np.hstack((np.expand_dims(wres_count*weights,axis=1)*X, \\\n",
    "                np.expand_dims(wres_zero*weights,axis=1)*Z, \\\n",
    "                               np.expand_dims(wres_theta,axis=1)))).sum(axis=0)\n",
    "\n",
    "    \n",
    "    reltol = tol\n",
    "    if factr < 1.0:\n",
    "        warnings.warn('Minimum value of factr is 1.0.')\n",
    "        factr = 1.0\n",
    "    if reltol is None:\n",
    "        reltol = factr*(np.finfo(float).eps)**(1/1.6)\n",
    "\n",
    "    \n",
    "    if dist not in ['poisson','negbin','geom']:\n",
    "        sys.exit(dist+\" method not yet implemented\")\n",
    "    if dist is 'poisson':\n",
    "        loglikfun = ziPoisson\n",
    "        gradfun = gradPoisson\n",
    "    elif dist is 'negbin':\n",
    "        loglikfun = ziNegBin\n",
    "        gradfun = gradNegBin\n",
    "    else:\n",
    "        loglikfun = ziGeom\n",
    "        gradfun = gradGeom\n",
    "        \n",
    "    if options is None:\n",
    "        options = {'disp': False, 'maxiter': 100000}\n",
    "\n",
    "\n",
    "    # starting values\n",
    "    if start is not None:\n",
    "        valid = True\n",
    "        if ('count' in start) is False:\n",
    "            valid = False\n",
    "            warnings.warn(\"invalid starting values, count model coefficients not specified\")\n",
    "            start['count'] = pd.Series(np.repeat(0,kx), index = X.columns.values)\n",
    "        if ('zero' in start) is False:\n",
    "            valid = False\n",
    "            warnings.warn(\"invalid starting values, zero model coefficients not specified\")\n",
    "            start['zero'] = pd.Series(np.repeat(0,kz), index = Z.columns.values)\n",
    "        if len(start['count']) != kx:\n",
    "            valid = False\n",
    "            warnings.warn(\"invalid starting values, wrong number of count model coefficients\")\n",
    "        if len(start['zero']) != kz:\n",
    "            valid = False\n",
    "            warnings.warn(\"invalid starting values, wrong number of zero model coefficients\")\n",
    "        if dist is 'negbin':\n",
    "            if ('theta' in start) is False:\n",
    "                start['theta'] = 1.0\n",
    "            start = {'zero':start['zero'], 'count':start['count'], 'theta' : (start['theta'][0]).astype(float)}\n",
    "        else:\n",
    "            start = {'zero':start['zero'], 'count':start['count']}    \n",
    "        \n",
    "        if valid is False:\n",
    "            start = None\n",
    "\n",
    "    if start is None:\n",
    "    ## EM estimation of starting values\n",
    "        \n",
    "        model_count = sm.GLM(endog = Y, exog = X, family = sm.families.Poisson(),\\\n",
    "                                  offset = offsetx , freq_weights = weights).fit()\n",
    "        model_zero = sm.GLM(Y0.astype(int), exog = Z, family=sm.families.Binomial(link = linkobj.linkclass), \\\n",
    "                   offset = offsetz , freq_weights = weights).fit()\n",
    "        start = {'zero':model_zero.params, 'count':model_count.params}\n",
    "        \n",
    "        if dist is 'negbin':\n",
    "            start['theta'] = 1.0 \n",
    "            \n",
    "        if (EM is True) and (dist is 'poisson'):\n",
    "            mui = model_count.predict()\n",
    "            probi = model_zero.predict()\n",
    "            probi = probi/(probi + (1-probi)*sp.stats.poisson.pmf(0, mui))\n",
    "            probi[Y1] = 0\n",
    "            probi\n",
    "            ll_new = loglikfun(np.hstack((start['count'].values,start['zero'].values)))\n",
    "            ll_old = 2 * ll_new\n",
    "    \n",
    "            while np.absolute((ll_old - ll_new)/ll_old) > reltol :\n",
    "                ll_old = ll_new\n",
    "                model_count = sm.GLM(endog = Y, exog = X, family = sm.families.Poisson(),\\\n",
    "                                  offset = offsetx , freq_weights = weights*(1-probi) \\\n",
    "                                              ).fit(start_params = start['count'].values)        \n",
    "                model_zero = sm.GLM(probi, exog = Z, family=sm.families.Binomial(link = linkobj.linkclass),\\\n",
    "                        offset = offsetz, freq_weights = weights \\\n",
    "                               ).fit(start_params = start['zero'].values)\n",
    "                start = {'zero':model_zero.params, 'count':model_count.params}\n",
    "\n",
    "                mui = model_count.predict()\n",
    "                probi = model_zero.predict()\n",
    "                probi = probi/(probi + (1-probi)*sp.stats.poisson.pmf(0, mui))\n",
    "                probi[Y1] = 0\n",
    "\n",
    "                ll_new = loglikfun(np.hstack((start['count'].values,start['zero'].values)))           \n",
    "            \n",
    "        if (EM is True) and (dist is 'geom'):\n",
    "            mui = model_count.predict()\n",
    "            probi = model_zero.predict()\n",
    "            probi = probi/(probi + (1-probi)*st.nbinom.pmf(0,*convert_params(theta = 1, mu = mui)))\n",
    "            probi[Y1] = 0\n",
    "            \n",
    "            ll_new = loglikfun(np.hstack((start['count'].values,start['zero'].values)))\n",
    "            ll_old = 2 * ll_new  \n",
    "                           \n",
    "            while np.absolute((ll_old - ll_new)/ll_old) > reltol :\n",
    "                ll_old = ll_new\n",
    "                model_count = sm.GLM(endog = Y, exog = X, family = sm.families.NegativeBinomial(alpha = 1.0),\\\n",
    "                                  offset = offsetx , freq_weights = weights*(1-probi)).fit(\\\n",
    "                                        #start_params = start['count'].values\n",
    "                                    sm.families.NegativeBinomial(alpha = 1.0\\\n",
    "                                                                ).starting_mu(y=start['count'].values))\n",
    "                model_zero = sm.GLM(probi, exog = Z, family=sm.families.Binomial(link = linkobj.linkclass),\\\n",
    "                        offset = offsetz, freq_weights = weights).fit(start_params = start['zero'].values)\n",
    "                start = {'zero':model_zero.params, 'count':model_count.params}\n",
    "\n",
    "                mui = model_count.predict()\n",
    "                probi = model_zero.predict()\n",
    "                probi = probi/(probi + (1-probi)*st.nbinom.pmf(0,*convert_params(theta = 1, mu = mui)))\n",
    "                probi[Y1] = 0                \n",
    "\n",
    "                ll_new = loglikfun(np.hstack((start['count'].values,start['zero'].values)))\n",
    "                \n",
    "        if (EM is True) and (dist is 'negbin'):\n",
    "            warnings.warn('EM estimation of starting values not available for Negetive Binomial.')\n",
    "            #mui = model_count.predict() # or model_count.mu\n",
    "            #probi = model_zero.predict()\n",
    "            #probi = probi/(probi + (1-probi)*st.nbinom.pmf(0,*convert_params(theta = start['theta'], mu = mui)))\n",
    "            #probi[Y1] = 0\n",
    "            \n",
    "            #ll_new = loglikfun(np.hstack((start['count'].values,start['zero'].values,np.log(start['theta']))))\n",
    "            #ll_old = 2 * ll_new \n",
    "            \n",
    "            #while np.absolute((ll_old - ll_new)/ll_old) > reltol :\n",
    "            #    ll_old = ll_new\n",
    "            #    model_count = sm.GLM(endog = Y, exog = X, family = \\\n",
    "            #                         sm.families.NegativeBinomial(alpha = start['theta']),\\\n",
    "            #                      offset = offsetx , freq_weights = weights*(1-probi), \\\n",
    "            #                          start_params = start['count']).fit()\n",
    "            #    model_zero = sm.GLM(probi, exog = Z, family=sm.families.Binomial(link = linkobj.linkclass),\\\n",
    "            #            offset = offsetz, freq_weights = weights, \\\n",
    "            #            start_params = start['zero']).fit()\n",
    "            #    start = {'zero':model_zero.params, 'count':model_count.params, 'theta':model_count.scale}\n",
    "    \n",
    "            #    mui = model_count.predict()\n",
    "            #    probi = model_zero.predict()\n",
    "            #    probi = probi/(probi + (1-probi)*st.nbinom.pmf(0,*convert_params(theta = start['theta'], mu = mui)))\n",
    "            #    probi[Y1] = 0\n",
    "\n",
    "            #    ll_new = loglikfun(np.hstack((start['count'].values,start['zero'].values,np.log(start['theta']))))\n",
    "    \n",
    "    ## ML Estimation\n",
    "    if (dist is 'negbin'):\n",
    "        x0 = np.hstack((start['count'].values,start['zero'].values,\\\n",
    "                                         np.log(start['theta'])))\n",
    "    else:\n",
    "        x0 = np.hstack((start['count'].values,start['zero'].values))\n",
    "\n",
    "    fit = sp.optimize.minimize(loglikfun, args=(-1.0,), x0 = x0, method=method, jac=gradfun, options=options)\n",
    "    \n",
    "    ## coefficients and covariances\n",
    "    coefc = pd.Series(data = fit.x[0:kx], index = X.columns.values)\n",
    "    coefz = pd.Series(data = fit.x[kx:kx+kz], index = Z.columns.values)\n",
    "\n",
    "    if method == 'L-BFGS-B':\n",
    "        vc_data = -fit.hess_inv.todense()\n",
    "    elif method == 'BFGS':\n",
    "        vc_data = -fit.hess_inv\n",
    "    else:\n",
    "        warnings.warn('Not tested for methods other than BFGS and L-BFGS-B.')\n",
    "    vc = pd.DataFrame(data = vc_data[np.arange(kx+kz)[:,None],np.arange(kx+kz)], \\\n",
    "                      index = np.append(X.columns.values, Z.columns.values),\\\n",
    "                 columns = np.append(X.columns.values, Z.columns.values))\n",
    "    if dist == 'negbin':\n",
    "        ntheta = kx + kz\n",
    "        theta = np.exp(fit.x[ntheta])\n",
    "        # Can hessian term for theta be negative? Using absolute here.\n",
    "        SE_logtheta = np.sqrt(np.abs(np.diagonal(vc_data)[ntheta]))\n",
    "    else:\n",
    "        theta = None\n",
    "        SE_logtheta = None\n",
    "    \n",
    "    ## fitted and residuals\n",
    "    mu = np.exp(np.dot(X,coefc)+offsetx)\n",
    "    phi = linkobj.link_inv(np.dot(Z,coefz)+offsetz)\n",
    "    Yhat = (1-phi) * mu\n",
    "    res = np.sqrt(weights) * (Y - Yhat)\n",
    "\n",
    "    ## effective observations\n",
    "    nobs = np.sum(weights > 0)\n",
    "    \n",
    "    start= {'count': coefc, 'zero' : coefz, 'theta': theta}\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class zipModel(object):\n",
    "    \n",
    "     #   def __init__(self):\n",
    "        \n",
    "            self.converged = fit.success\n",
    "            self.iters = fit.nit;                   # number of iterations for convergence\n",
    "            self.loglike = fit.fun;                 # log-likelihood\n",
    "        \n",
    "            self.coeff_count = coefc  # coefficient vector for count model\n",
    "            self.coeff_zero = coefz   # coefficient vector for zero-inflation model\n",
    "        \n",
    "            self.theta = theta if (dist is 'negbin') else None\n",
    "        \n",
    "            self.residuals = np.array(res)    # function needs to be implemented\n",
    "            self.vcov = vc\n",
    "        \n",
    "            # string vars\n",
    "            self.var_names_count = X.columns.values       # variable names, intercept in feat_names[0]\n",
    "            self.var_names_zero = Z.columns.values        # var name for zero-inflated variable\n",
    "            self.response_name = y.columns.values[0]          # name of the response variable\n",
    "        \n",
    "            self.call = ''\n",
    "            \n",
    "            self.coefficients = {'count':coefc ,'zero': coefz}\n",
    "            self.residuals = res\n",
    "            self.fitted_values = Yhat\n",
    "            self.optim = fit\n",
    "            self.method = method\n",
    "            self.comtrol = ''\n",
    "            self.start = start\n",
    "            self.weights = []\n",
    "            self.offset = []\n",
    "            self.n = nobs\n",
    "            self.df_null = nobs - 2\n",
    "            self.df_residual = \n",
    "            self.terms = ''\n",
    "            self.theta = theta\n",
    "            self.SE_logtheta = \n",
    "            self.loglik = ''\n",
    "            self.vcov = vc\n",
    "            self.dist = dist\n",
    "            self.link = linkstr\n",
    "            self.linkinv = \n",
    "            self.converged = fit.success\n",
    "            self.call = ''\n",
    "            self.formula = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:362: UserWarning: EM estimation of starting values not available for Negetive Binomial.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'count': Intercept              0.941806\n",
       " health[T.excellent]   -0.329442\n",
       " health[T.poor]         0.328911\n",
       " gender[T.male]        -0.124682\n",
       " privins[T.yes]         0.218386\n",
       " hosp                   0.222516\n",
       " numchron               0.173664\n",
       " school                 0.026673\n",
       " dtype: float64,\n",
       " 'theta': 1.2587589747287193,\n",
       " 'zero': Intercept             -5.043172\n",
       " health[T.excellent]    1.082341\n",
       " health[T.poor]         1.619519\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Lines below will not go inside the function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "df = pd.read_csv('DebTrivedi.csv',index_col = [0])\n",
    "sel = np.array([1, 6, 7, 8, 13, 15, 18])-1\n",
    "df = df.iloc[:,sel]\n",
    "# produce design matrices from R-style formula\n",
    "X_formula = 'ofp ~ hosp + health + numchron + gender + school + privins'\n",
    "y, X = patsy.dmatrices(X_formula, df, return_type='dataframe')\n",
    "Z_formula = 'ofp ~ health'\n",
    "Z = patsy.dmatrices(Z_formula, df, return_type='dataframe')[1]\n",
    "zeroinfl(y,X,Z,dist='negbin',method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficients = list(count = coefc, zero = coefz),\n",
    "    residuals = res,\n",
    "    fitted.values = Yhat,\n",
    "    optim = fit,\n",
    "    method = method,\n",
    "    control = ocontrol,\n",
    "    start = start,\n",
    "    weights = if(identical(as.vector(weights), rep.int(1L, n))) NULL else weights,\n",
    "    offset = list(count = if(identical(offsetx, rep.int(0, n))) NULL else offsetx,\n",
    "      zero = if(identical(offsetz, rep.int(0, n))) NULL else offsetz),\n",
    "    n = nobs,\n",
    "    df.null = nobs - 2,\n",
    "    df.residual = nobs - (kx + kz + (dist == \"negbin\")),\n",
    "    terms = list(count = mtX, zero = mtZ, full = mt),\n",
    "    theta = theta,\n",
    "    SE.logtheta = SE.logtheta,\n",
    "    loglik = fit$value,\n",
    "    vcov = vc,\n",
    "    dist = dist,\n",
    "    link = linkstr,\n",
    "    linkinv = linkinv,\n",
    "    converged = fit$convergence < 1,\n",
    "    call = cl,\n",
    "    formula = ff,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
