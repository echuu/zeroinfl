{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Lines below will not go inside the function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "df = pd.read_csv('DebTrivedi.csv',index_col = [0])\n",
    "sel = np.array([1, 6, 7, 8, 13, 15, 18])-1\n",
    "df = df.iloc[:,sel]\n",
    "# produce design matrices from R-style formula\n",
    "X_formula = 'ofp ~ hosp + health + numchron + gender + school + privins'\n",
    "y, X = patsy.dmatrices(X_formula, df, return_type='dataframe')\n",
    "Z_formula = 'ofp ~ health'\n",
    "Z = patsy.dmatrices(Z_formula, df, return_type='dataframe')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function starts\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## convenience variables\n",
    "Y = np.squeeze(y.values)\n",
    "n = len(Y)\n",
    "kx = X.shape[1] # Number of columns in X\n",
    "kz = Z.shape[1]\n",
    "Y0 = Y <= 0\n",
    "Y1 = Y > 0\n",
    "\n",
    "offsetx = np.zeros(n)\n",
    "offsetz = np.zeros(n)\n",
    "weights = np.ones(n)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import scipy as sp\n",
    "\n",
    "def ziPoisson(parms, sign = 1.0):\n",
    "    ## count mean\n",
    "    mu = np.exp(np.dot(X,parms[np.arange(kx)]) + offsetx)\n",
    "    ## binary mean\n",
    "    phi = linkinv(np.dot(Z, parms[np.arange(kx,kx+kz)]) + offsetz)\n",
    "    ## log-likelihood for y = 0 and y >= 1\n",
    "    loglik0 = np.log( phi + np.exp( np.log(1-phi) - mu ) ) ## -mu = dpois(0, lambda = mu, log = TRUE)\n",
    "    loglik1 = np.log(1-phi) + sp.stats.poisson.logpmf(Y, mu)\n",
    "    ## collect and return\n",
    "    loglik = np.dot(weights[Y0],loglik0[Y0])+np.dot(weights[Y1],loglik1[Y1])\n",
    "    return sign*loglik\n",
    "\n",
    "def gradPoisson(parms, sign = 1.0):\n",
    "    ## count mean\n",
    "    eta = np.dot(X,parms[np.arange(kx)]) + offsetx\n",
    "    mu = np.exp(eta)\n",
    "    ## binary mean\n",
    "    etaz = np.dot(Z, parms[np.arange(kx,kx+kz)]) + offsetz\n",
    "    muz = linkinv(etaz)\n",
    "    ## densities at 0\n",
    "    clogdens0 = -mu\n",
    "    dens0 = muz*(1-Y1.astype(float)) + np.exp(np.log(1 - muz) + clogdens0)\n",
    "    ## working residuals  \n",
    "    wres_count = np.where(Y1,Y-mu,-np.exp(-np.log(dens0) + \n",
    "                                          np.log(1 - muz) + clogdens0 + np.log(mu))) \n",
    "    link_etaz = np.exp(etaz)/(1+np.exp(etaz))**2\n",
    "    wres_zero  = np.where(Y1,-1/(1-muz) * link_etaz, \\\n",
    "                          (link_etaz - np.exp(clogdens0) * link_etaz)/dens0)\n",
    "    \n",
    "    \n",
    "    return sign*(np.hstack((np.expand_dims(wres_count*weights,axis=1)*X, \\\n",
    "                np.expand_dims(wres_zero*weights,axis=1)*Z))).sum(axis=0)\n",
    "\n",
    "\n",
    "## Parameters: mention these in class definition\n",
    "##-----------------------------------------------\n",
    "linkinv = sp.special.expit\n",
    "linkobj = sp.special.logit\n",
    "linkstr = 'logit'\n",
    "reltol =  (np.finfo(float).eps)**(1/1.6)\n",
    "method = 'BFGS'\n",
    "dist = 'Poisson'\n",
    "##-----------------------------------------------\n",
    "loglikfun = ziPoisson\n",
    "gradfun = gradPoisson\n",
    "\n",
    "linkclass = sm.genmod.families.links.logit\n",
    "\n",
    "## EM estimation of starting values\n",
    "model_count = sm.GLM(endog = Y, exog = X, family = sm.families.Poisson(),\\\n",
    "                                  offset = offsetx , freq_weights = weights).fit()\n",
    "model_zero = sm.GLM(Y0.astype(int), exog = Z, family=sm.families.Binomial(link = linkclass), \\\n",
    "                   offset = offsetz , freq_weights = weights).fit()\n",
    "start = {'zero':model_zero.params, 'count':model_count.params}\n",
    "\n",
    "mui = model_count.predict()\n",
    "probi = model_zero.predict()\n",
    "probi = probi/(probi + (1-probi)*sp.stats.poisson.pmf(0, mui))\n",
    "probi[Y1] = 0\n",
    "\n",
    "ll_new = loglikfun(np.hstack((start['count'].values,start['zero'].values)))\n",
    "ll_old = 2 * ll_new\n",
    "\n",
    "while np.absolute((ll_old - ll_new)/ll_old) > reltol :\n",
    "    ll_old = ll_new\n",
    "    model_count = poisson_mod = sm.GLM(endog = Y, exog = X, family = sm.families.Poisson(),\\\n",
    "                                  offset = offsetx , freq_weights = weights*(1-probi), \\\n",
    "                                      start_params = start['count']).fit()\n",
    "    model_zero = sm.GLM(probi, exog = Z, family=sm.families.Binomial(link = linkclass),\\\n",
    "                        offset = offsetz, freq_weights = weights, \\\n",
    "                        start_params = start['zero']).fit()\n",
    "    start = {'zero':model_zero.params, 'count':model_count.params}\n",
    "\n",
    "    mui = model_count.predict()\n",
    "    probi = model_zero.predict()\n",
    "    probi = probi/(probi + (1-probi)*sp.stats.poisson.pmf(0, mui))\n",
    "    probi[Y1] = 0\n",
    "\n",
    "    ll_new = loglikfun(np.hstack((start['count'].values,start['zero'].values)))\n",
    "    \n",
    "## ML Estimation\n",
    "fit = sp.optimize.minimize(loglikfun, args=(-1.0,), x0 = np.hstack((start['count'].values,start['zero'].values)),\\\n",
    "            method='BFGS', jac=gradfun, options={'disp': False, 'maxiter': 10000}, tol = reltol)\n",
    "\n",
    "## coefficients and covariances\n",
    "coefc = pd.Series(data = fit.x[0:kx], index = X.columns.values)\n",
    "coefz = pd.Series(data = fit.x[kx:kx+kz], index = Z.columns.values)\n",
    "vc = pd.DataFrame(data = -fit.hess_inv, index = np.append(X.columns.values, Z.columns.values),\\\n",
    "                 columns = np.append(X.columns.values, Z.columns.values))\n",
    "\n",
    "## fitted and residuals\n",
    "mu = np.exp(np.dot(X,coefc)+offsetx)\n",
    "phi = linkinv(np.dot(Z,coefz)+offsetz)\n",
    "Yhat = (1-phi) * mu\n",
    "res = np.sqrt(weights) * (Y - Yhat)\n",
    "\n",
    "## effective observations\n",
    "nobs = np.sum(weights > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rval = list(coefficients = list(count = coefc, zero = coefz),\n",
    "    residuals = res,\n",
    "    fitted.values = Yhat,\n",
    "    optim = fit,\n",
    "    method = method,\n",
    "    ### control = ocontrol,\n",
    "    start = start,\n",
    "    weights = if(identical(as.vector(weights), rep.int(1L, n))) NULL else weights,\n",
    "    offset = list(count = if(identical(offsetx, rep.int(0, n))) NULL else offsetx,\n",
    "      zero = if(identical(offsetz, rep.int(0, n))) NULL else offsetz),\n",
    "    n = nobs,\n",
    "    df.null = nobs - 2,\n",
    "    df.residual = nobs - (kx + kz + (dist == \"negbin\")),\n",
    "    terms = list(count = mtX, zero = mtZ, full = mt),\n",
    "    ###  theta = theta,\n",
    "    ### SE.logtheta = SE.logtheta,\n",
    "    loglik = fit$value,\n",
    "    vcov = vc,\n",
    "    dist = dist,\n",
    "    link = linkstr,\n",
    "    linkinv = linkinv,\n",
    "    converged = fit$convergence < 1,\n",
    "    ### call = cl,\n",
    "    ### formula = ff,\n",
    "    ### levels = .getXlevels(mt, mf),\n",
    "    ### contrasts = list(count = attr(X, \"contrasts\"), zero = attr(Z, \"contrasts\"))\n",
    "    )\n",
    "    ### if(model) rval$model <- mf\n",
    "    if(y) rval$y <- Y\n",
    "    if(x) rval$x <- list(count = X, zero = Z)\n",
    "      \n",
    "    class(rval) <- \"ZinfModel\"\n",
    "    return(rval)\n",
    "    }`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments:\n",
    "ZinfModel: Class name is more inclusive if binomial and geometric inflated models are added in future. Also first alphabet in uppercase is standard practice in naming python classes.\n",
    "\n",
    "No need to add '###' variables above in class definition.\n",
    "\n",
    "If possible try for the print output to look similar to python sm.glm output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
