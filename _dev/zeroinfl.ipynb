{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "nbpresent": {
     "id": "c57c86d6-b499-4734-af33-9b8f24d422b3"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import sys\n",
    "import warnings\n",
    "import inspect\n",
    "import patsy\n",
    "from decimal import Decimal\n",
    "from IPython.core.display import display, HTML\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import nbinom\n",
    "\n",
    "FLOAT_EPS = np.finfo(float).eps\n",
    "pd.options.display.float_format = '{:,.12f}'.format\n",
    "\n",
    "__all__ = ['ZeroInflated']\n",
    "\n",
    "\n",
    "class LinkClass(object):\n",
    "    def __init__(self):\n",
    "        return NotImplementedError\n",
    "    def link(self, mu):\n",
    "        return NotImplementedError\n",
    "    def link_inv(self, eta):\n",
    "        return NotImplementedError\n",
    "    def link_inv_deriv(self, eta):\n",
    "        return NotImplementedError\n",
    "        \n",
    "    \n",
    "class Logit(LinkClass):\n",
    "    def __init__(self):\n",
    "        self.linkclass = sm.genmod.families.links.logit\n",
    "    def link(self, p):\n",
    "        return np.log(p/(1.0-p))\n",
    "        #return sp.special.logit(p)\n",
    "    def link_inv(self, eta):\n",
    "        thresh = 30.0\n",
    "        eta = np.minimum(np.maximum(eta,-thresh), thresh)\n",
    "        exp_eta = np.exp(-eta)\n",
    "        return 1.0/(1.0+exp_eta)\n",
    "        #return sp.special.expit(eta)\n",
    "    def link_inv_deriv(self, eta):\n",
    "        thresh = 30.0\n",
    "        eta[abs(eta) > thresh] = FLOAT_EPS\n",
    "        return np.exp(eta)/(1+np.exp(eta))**2\n",
    "    def __repr__(self):\n",
    "        display_string = f\"\\n    linkstr: logit\"\n",
    "        display_string += '\\n    link: log(p/(1-p))'\n",
    "        display_string += '\\n    linkinv: exp(eta)/(1+exp(eta))'\n",
    "        return display_string\n",
    "\n",
    "class Probit(LinkClass):\n",
    "    def __init__(self):\n",
    "        self.linkclass = sm.genmod.families.links.probit\n",
    "    def link(self, mu):\n",
    "        return st.norm.ppf(mu)\n",
    "    def link_inv(self, eta):\n",
    "        thresh = -st.norm.ppf(FLOAT_EPS)\n",
    "        eta = np.minimum(np.maximum(eta,-thresh),thresh)\n",
    "        return st.norm.cdf(eta)\n",
    "    def link_inv_deriv(self, eta):\n",
    "        return np.maximum(st.norm.pdf(eta),FLOAT_EPS)\n",
    "    def __repr__(self):\n",
    "        display_string = f\"\\n    linkstr: probit\"\n",
    "        display_string += '\\n    link: norm.ppf(mu)'\n",
    "        display_string += '\\n    linkinv: norm.cdf(eta)'\n",
    "        return display_string\n",
    "    \n",
    "class CLogLog(LinkClass):\n",
    "    def __init__(self):\n",
    "        self.linkclass = sm.genmod.families.links.cloglog\n",
    "    def link(self, mu):\n",
    "        return np.log(-np.log(1 - mu))\n",
    "    def link_inv(self, eta):\n",
    "        return np.maximum(np.minimum(-np.expm1(-np.exp(eta)),1-FLOAT_EPS),FLOAT_EPS)\n",
    "    def link_inv_deriv(self, eta):\n",
    "        eta = np.minimum(eta,700)\n",
    "        return np.maximum(np.exp(eta)*np.exp(-np.exp(eta)),FLOAT_EPS)\n",
    "    def __repr__(self):\n",
    "        display_string = f\"\\n    linkstr: cloglog\"\n",
    "        display_string += '\\n    link: log(-log(1 - mu))'\n",
    "        display_string += '\\n    linkinv: 1-exp(-exp(eta))'\n",
    "        return display_string\n",
    "    \n",
    "class Cauchit(LinkClass):\n",
    "    def __init__(self):\n",
    "        self.linkclass = sm.genmod.families.links.cauchy\n",
    "    def link(self, mu):\n",
    "        return st.cauchy.ppf(mu)\n",
    "    def link_inv(self, eta):\n",
    "        thresh = -st.cauchy.ppf(FLOAT_EPS)\n",
    "        eta = np.minimum(np.maximum(eta,-thresh),thresh)\n",
    "        return st.cauchy.cdf(eta)\n",
    "    def link_inv_deriv(self, eta):\n",
    "        return nnp.maximum(st.cauchy.pdf(eta),FLOAT_EPS)\n",
    "    def __repr__(self):\n",
    "        display_string = f\"\\n    linkstr: cauchit\"\n",
    "        display_string += '\\n    link: cauchy.ppf(mu)'\n",
    "        display_string += '\\n    linkinv: cauchy.cdf(eta)'\n",
    "        return display_string\n",
    "    \n",
    "class Log(LinkClass):\n",
    "    def __init__(self):\n",
    "        self.linkclass = sm.genmod.families.links.log\n",
    "    def link(self, mu):\n",
    "        return np.log(mu)\n",
    "    def link_inv(self, eta):\n",
    "        return np.maximum(np.exp(eta), FLOAT_EPS)\n",
    "    def link_inv_deriv(self, eta):\n",
    "        return np.maximum(np.exp(eta), FLOAT_EPS)\n",
    "    def __repr__(self):\n",
    "        display_string = f\"\\n    linkstr: log\"\n",
    "        display_string += '\\n    link: log(mu)'\n",
    "        display_string += '\\n    linkinv: exp(eta)'\n",
    "        return display_string\n",
    "    \n",
    "\n",
    "\n",
    "class ZeroInflated(object):\n",
    "    __doc__ = \"\"\"\n",
    "    Zero Inflated model for count data\n",
    "    %(params)s\n",
    "    %(extra_params)s\n",
    "    Attributes\n",
    "    -----------\n",
    "    formula_str : string\n",
    "        A reference to the endogenous response variable.\n",
    "    data : pandas dataframe\n",
    "        A reference to the exogenous design.\n",
    "    dist: string\n",
    "        A reference to the zero-inflated exogenous design.\n",
    "    link: string\n",
    "        A reference to \n",
    "    \"\"\"\n",
    "    def __init__(self, formula_str, data, dist = 'poisson', offsetx = None, offsetz = None,\n",
    "                 link = 'logit', weights = None, missing='none', **kwargs):\n",
    "        self._set_data(formula_str, data, missing)\n",
    "        self.terms = {'Y':self.endog.columns.values[0],'X':self.X.columns.values,\\\n",
    "                      'Z':self.Z.columns.values}\n",
    "        self.formula = formula_str\n",
    "        self.dist = self._dist_processing(dist)\n",
    "        self.link = self._link_processing(link)\n",
    "        self.n = len(self.endog)\n",
    "        self._set_wt_offset(weights, offsetx, offsetz)\n",
    "        self.linkobj = self._LinkClass_processing(self.link)\n",
    "        self._set_loglik(self.dist)\n",
    "        self.call = f\"ZeroInflated(formula_str='{formula_str}', data={self._retrieve_name(data)}, dist='{dist}', offsetx={offsetx}, offsetz={offsetz},\"\n",
    "        self.call = self.call + f\" link='{link}', weights={weights}, missing='{missing}')\"\n",
    "        \n",
    "        # Convenience variables\n",
    "        self.kx = self.X.shape[1]\n",
    "        self.kz = self.Z.shape[1]\n",
    "        self.Y = np.squeeze(self.endog)\n",
    "        self.Y0 = self.Y <= 0\n",
    "        self.Y1 = self.Y > 0\n",
    "        self.EM = True\n",
    "        self.reltol = (np.finfo(float).eps)**(1/1.6)       \n",
    "        \n",
    "        \n",
    "    def print_obj(self):\n",
    "        print(self)   \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def _retrieve_name(self, var):\n",
    "        \"\"\"\n",
    "        Gets the name of var. Does it from the out most frame inner-wards.\n",
    "        :param var: variable to get name from.\n",
    "        :return: string\n",
    "        \"\"\"\n",
    "        for fi in reversed(inspect.stack()):\n",
    "            names = [var_name for var_name, var_val in fi.frame.f_locals.items() if var_val is var]\n",
    "            if len(names) > 0:\n",
    "                return names[-1]\n",
    "        \n",
    "    def _set_data(self, formula_str, data, missing):\n",
    "        self.endog, self.X, self.Z = self.formula_processing(formula_str, data, missing=missing) \n",
    "     \n",
    "           \n",
    "    def _set_wt_offset(self, weights, offsetx, offsetz):\n",
    "        ## weights and offset\n",
    "        \n",
    "        if weights is None:\n",
    "            weights = 1.0\n",
    "        weights = np.ndarray.flatten(np.array(weights))\n",
    "        if weights.size == 1:\n",
    "            weights = np.repeat(weights,self.n)\n",
    "        weights = pd.Series(data = weights, index = self.X.index)\n",
    "\n",
    "        if offsetx is None:\n",
    "            offsetx = 0.0\n",
    "        offsetx = np.ndarray.flatten(np.array(offsetx))\n",
    "        if offsetx.size == 1:\n",
    "            offsetx = np.repeat(offsetx,self.n)\n",
    "\n",
    "        if offsetz is None:\n",
    "            offsetz = 0.0\n",
    "        offsetz = np.ndarray.flatten(np.array(offsetz))\n",
    "        if offsetz.size == 1:\n",
    "            offsetz = np.repeat(offsetz,self.n)\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.offsetx = offsetx\n",
    "        self.offsetz = offsetz\n",
    "        \n",
    "    def _set_loglik(self, dist):\n",
    "        if dist is 'poisson':\n",
    "            self.loglikfun = self.ziPoisson\n",
    "            self.gradfun = self.gradPoisson\n",
    "        elif dist is 'negbin':\n",
    "            self.loglikfun = self.ziNegBin\n",
    "            self.gradfun = self.gradNegBin\n",
    "        else:\n",
    "            self.loglikfun = self.ziGeom\n",
    "            self.gradfun = self.gradGeom\n",
    "        \n",
    "    def ziPoisson(self, parms, sign = 1.0):\n",
    "        \"\"\"\n",
    "        Log-likelihood of Zero Inflated Poisson.\n",
    "        \"\"\"\n",
    "        \n",
    "        ## count mean\n",
    "        mu = np.exp(np.dot(self.X,parms[np.arange(self.kx)]) + self.offsetx)\n",
    "        ## binary mean\n",
    "        phi = self.linkobj.link_inv(np.dot(self.Z, parms[np.arange(self.kx,self.kx+self.kz)]) +\\\n",
    "                                    self.offsetz)\n",
    "        ## log-likelihood for y = 0 and y >= 1\n",
    "        loglik0 = np.log(phi + np.exp(np.log(1-phi) - mu)) \n",
    "        loglik1 = np.log(1-phi) + sp.stats.poisson.logpmf(self.Y, mu)\n",
    "        ## collect and return\n",
    "        loglik = np.dot(self.weights[self.Y0],loglik0[self.Y0])+np.dot(self.weights[self.Y1],loglik1[self.Y1])\n",
    "        return sign*loglik\n",
    "\n",
    "    def gradPoisson(self, parms, sign = 1.0):\n",
    "        \"\"\"\n",
    "        Gradient of Zero Inflated Poisson Log-likelihood.\n",
    "        \"\"\"\n",
    "        \n",
    "        ## count mean\n",
    "        eta = np.dot(self.X,parms[np.arange(self.kx)]) + self.offsetx\n",
    "        mu = np.exp(eta)\n",
    "        ## binary mean\n",
    "        etaz = np.dot(self.Z, parms[np.arange(self.kx,self.kx+self.kz)]) + self.offsetz\n",
    "        muz = self.linkobj.link_inv(etaz)\n",
    "        ## densities at 0\n",
    "        clogdens0 = -mu\n",
    "        dens0 = muz*(1-self.Y1.astype(float)) + np.exp(np.log(1 - muz) + clogdens0)\n",
    "        ## working residuals  \n",
    "        wres_count = np.where(self.Y1,self.Y-mu,-np.exp(-np.log(dens0) + \n",
    "                                          np.log(1 - muz) + clogdens0 + np.log(mu))) \n",
    "        link_etaz = self.linkobj.link_inv_deriv(etaz)\n",
    "        wres_zero  = np.where(self.Y1,-1/(1-muz) * link_etaz, \\\n",
    "                          (link_etaz - np.exp(clogdens0) * link_etaz)/dens0)   \n",
    "    \n",
    "        return sign*(np.hstack((np.expand_dims(wres_count*self.weights,axis=1)*self.X, \\\n",
    "                np.expand_dims(wres_zero*self.weights,axis=1)*self.Z))).sum(axis=0)\n",
    "    \n",
    "    def ziNegBin(self, parms, sign = 1.0):\n",
    "        \"\"\"\n",
    "        Log-Likelihood of Zero Inflated Negative Binomial.\n",
    "        \"\"\"\n",
    "        ## count mean\n",
    "        mu = np.exp(np.dot(self.X,parms[np.arange(self.kx)]) + self.offsetx)\n",
    "        ## binary mean\n",
    "        phi = self.linkobj.link_inv(np.dot(self.Z, parms[np.arange(self.kx,self.kx+self.kz)]) + self.offsetz)\n",
    "        ## negbin size\n",
    "        theta = np.exp(parms[self.kx+self.kz])\n",
    "    \n",
    "        ## log-likelihood for y = 0 and y >= 1 sp.stats.poisson.logpmf(Y, mu)\n",
    "        loglik0 = np.log(phi + np.exp(np.log(1-phi) + \\\n",
    "                                   st.nbinom.logpmf(0,*self.convert_params(theta = theta, mu = mu)) ) )\n",
    "        loglik1 = np.log(1-phi) + st.nbinom.logpmf(self.Y,*self.convert_params(theta = theta, mu = mu))\n",
    "\n",
    "        ## collect and return\n",
    "        loglik = np.dot(self.weights[self.Y0],loglik0[self.Y0])+np.dot(self.weights[self.Y1],loglik1[self.Y1])\n",
    "        return sign*loglik\n",
    "  \n",
    "    def ziGeom(self, parms, sign = 1.0):\n",
    "        return self.ziNegBin(np.hstack((parms, 0)), sign)\n",
    "    \n",
    "    def gradGeom(self, parms, sign = 1.0):\n",
    "        \"\"\"\n",
    "        Gradient of Zero Inflated Geometric Log-likelihood.\n",
    "        \n",
    "        \"\"\"\n",
    "        ## count mean\n",
    "        eta = np.dot(self.X,parms[np.arange(self.kx)]) + self.offsetx\n",
    "        mu = np.exp(eta)\n",
    "        ## binary mean\n",
    "        etaz = np.dot(self.Z, parms[np.arange(self.kx,self.kx+self.kz)]) + self.offsetz\n",
    "        muz = self.linkobj.link_inv(etaz) \n",
    "\n",
    "        ## densities at 0\n",
    "        clogdens0 = st.nbinom.logpmf(0,*self.convert_params(theta = 1, mu = mu))\n",
    "        dens0 = muz*(1-self.Y1.astype(float)) + np.exp(np.log(1 - muz) + clogdens0)\n",
    "\n",
    "        ## working residuals  \n",
    "        wres_count = np.where(self.Y1,self.Y - mu*(self.Y + 1)/(mu + 1), \\\n",
    "                              -np.exp(-np.log(dens0) + np.log(1 - muz) + clogdens0 +\\\n",
    "                                      -np.log(mu+1) + np.log(mu))) \n",
    "        link_etaz = self.linkobj.link_inv_deriv(etaz)\n",
    "        wres_zero  = np.where(self.Y1,-1/(1-muz) * link_etaz, \\\n",
    "                          (link_etaz - np.exp(clogdens0) * link_etaz)/dens0)\n",
    "      \n",
    "        return sign*(np.hstack((np.expand_dims(wres_count*self.weights,axis=1)*self.X, \\\n",
    "                np.expand_dims(wres_zero*self.weights,axis=1)*self.Z))).sum(axis=0)\n",
    "    \n",
    "    def gradNegBin(self, parms, sign = 1.0): \n",
    "        \"\"\"\n",
    "        Gradient of Zero Inflated Negative Binomial Log-likelihood. \n",
    "        (Negetive Binomial2 to be specific.)\n",
    "        \n",
    "        \"\"\"\n",
    "        ## count mean\n",
    "        eta = np.dot(self.X,parms[np.arange(self.kx)]) + self.offsetx\n",
    "        mu = np.exp(eta)\n",
    "        ## binary mean\n",
    "        etaz = np.dot(self.Z, parms[np.arange(self.kx,self.kx+self.kz)]) + self.offsetz\n",
    "        muz = self.linkobj.link_inv(etaz)   \n",
    "        ## negbin size\n",
    "        theta = np.exp(parms[self.kx+self.kz])\n",
    "\n",
    "        ## densities at 0\n",
    "        clogdens0 = st.nbinom.logpmf(0,*self.convert_params(theta = theta, mu = mu))\n",
    "        dens0 = np.array(muz*(1-self.Y1.astype(float)) + np.exp(np.log(1 - muz) + clogdens0))\n",
    "        \n",
    "        #print('clogdens0')\n",
    "        #print(clogdens0[1])\n",
    "        #print(type(clogdens0))\n",
    "        #print('dens0')\n",
    "        #print(dens0[1])\n",
    "        #print(type(dens0))\n",
    "        \n",
    "        ## working residuals  \n",
    "        wres_count = np.where(self.Y1,self.Y - mu*(self.Y + theta)/(mu + theta), \\\n",
    "                              -np.exp(-np.log(dens0) + np.log(1 - muz) + clogdens0 + np.log(theta) \\\n",
    "                                      -np.log(mu+theta) + np.log(mu))) \n",
    "        link_etaz = self.linkobj.link_inv_deriv(etaz)\n",
    "        wres_zero  = np.where(self.Y1,-1/(1-muz) * link_etaz, \\\n",
    "                          (link_etaz - np.exp(clogdens0) * link_etaz)/dens0)\n",
    "        \n",
    "        wres_theta = theta*np.where(self.Y1, sp.special.digamma(self.Y + theta) - sp.special.digamma(theta) +\\\n",
    "                                   np.log(theta) - np.log(mu + theta) + 1 - (self.Y + theta)/(mu + theta),\\\n",
    "                                   np.exp(-np.log(dens0) + np.log(1 - muz) + clogdens0)*\\\n",
    "                                   (np.log(theta) - np.log(mu + theta) + 1 - theta/(mu+theta) ) )\n",
    "        \n",
    "        return sign*(np.hstack((np.expand_dims(wres_count*self.weights,axis=1)*self.X, \\\n",
    "                np.expand_dims(wres_zero*self.weights,axis=1)*self.Z, \\\n",
    "                               np.expand_dims(wres_theta,axis=1)))).sum(axis=0)\n",
    "    \n",
    "    def EM_estimate(self):\n",
    "        ## EM estimation of starting values\n",
    "        \n",
    "        model_count = sm.GLM(endog = self.Y, exog = self.X, family = sm.families.Poisson(),\\\n",
    "                                  offset = self.offsetx , freq_weights = self.weights).fit()\n",
    "        model_zero = sm.GLM(self.Y0.astype(int), exog = self.Z, family=sm.families.Binomial(link = self.linkobj.linkclass), \\\n",
    "                   offset = self.offsetz , freq_weights = self.weights).fit()\n",
    "        self.start = {'zero':model_zero.params, 'count':model_count.params}\n",
    "        \n",
    "        if self.dist is 'negbin':\n",
    "            self.start['theta'] = 1.0 \n",
    "            \n",
    "        if (self.EM is True) and (self.dist is 'poisson'):\n",
    "            mui = model_count.predict()\n",
    "            probi = model_zero.predict()\n",
    "            probi = probi/(probi + (1-probi)*sp.stats.poisson.pmf(0, mui))\n",
    "            probi[self.Y1] = 0\n",
    "            probi\n",
    "            ll_new = self.loglikfun(np.hstack((self.start['count'].values,self.start['zero'].values)))\n",
    "            ll_old = 2 * ll_new\n",
    "    \n",
    "            while np.absolute((ll_old - ll_new)/ll_old) > self.reltol :\n",
    "                ll_old = ll_new\n",
    "                model_count = sm.GLM(endog = self.Y, exog = self.X, family = sm.families.Poisson(),\\\n",
    "                                  offset = self.offsetx , freq_weights = self.weights*(1-probi) \\\n",
    "                                              ).fit(start_params = self.start['count'].values)        \n",
    "                model_zero = sm.GLM(probi, exog = self.Z, family=sm.families.Binomial(link = self.linkobj.linkclass),\\\n",
    "                        offset = self.offsetz, freq_weights = self.weights \\\n",
    "                               ).fit(start_params = self.start['zero'].values)\n",
    "                self.start = {'zero':model_zero.params, 'count':model_count.params}\n",
    "\n",
    "                mui = model_count.predict()\n",
    "                probi = model_zero.predict()\n",
    "                probi = probi/(probi + (1-probi)*sp.stats.poisson.pmf(0, mui))\n",
    "                probi[self.Y1] = 0\n",
    "\n",
    "                ll_new = self.loglikfun(np.hstack((self.start['count'].values,self.start['zero'].values)))           \n",
    "            \n",
    "        if (self.EM is True) and (self.dist is 'geom'):\n",
    "            mui = model_count.predict()\n",
    "            probi = model_zero.predict()\n",
    "            probi = probi/(probi + (1-probi)*st.nbinom.pmf(0,*self.convert_params(theta = 1, mu = mui)))\n",
    "            probi[self.Y1] = 0\n",
    "            \n",
    "            ll_new = self.loglikfun(np.hstack((self.start['count'].values,self.start['zero'].values)))\n",
    "            ll_old = 2 * ll_new  \n",
    "                           \n",
    "            while np.absolute((ll_old - ll_new)/ll_old) > self.reltol :\n",
    "                ll_old = ll_new\n",
    "                model_count = sm.GLM(endog = self.Y, exog = self.X, family = sm.families.NegativeBinomial(alpha = 1.0),\\\n",
    "                                  offset = self.offsetx , freq_weights = self.weights*(1-probi)).fit(\\\n",
    "                                        start_params = self.start['count'].values)\n",
    "                                    #sm.families.NegativeBinomial(alpha = 1.0\\\n",
    "                                    #                            ).starting_mu(y=self.start['count'].values))\n",
    "                model_zero = sm.GLM(probi, exog = self.Z, family=sm.families.Binomial(link = self.linkobj.linkclass),\\\n",
    "                        offset = self.offsetz, freq_weights = self.weights).fit(start_params = self.start['zero'].values)\n",
    "                self.start = {'zero':model_zero.params, 'count':model_count.params}\n",
    "\n",
    "                mui = model_count.predict()\n",
    "                probi = model_zero.predict()\n",
    "                probi = probi/(probi + (1-probi)*st.nbinom.pmf(0,*self.convert_params(theta = 1, mu = mui)))\n",
    "                probi[self.Y1] = 0                \n",
    "\n",
    "                ll_new = self.loglikfun(np.hstack((self.start['count'].values,self.start['zero'].values)))\n",
    "                \n",
    "        if (self.EM is True) and (self.dist is 'negbin'):\n",
    "            warnings.warn('EM estimation of starting values not optimal for Negetive Binomial.')\n",
    "            mui = model_count.predict() # or model_count.mu\n",
    "            probi = model_zero.predict()\n",
    "            probi = probi/(probi + (1-probi)*st.nbinom.pmf(0,*self.convert_params(theta = self.start['theta'], mu = mui)))\n",
    "            probi[self.Y1] = 0\n",
    "            \n",
    "            ll_new = self.loglikfun(np.hstack((self.start['count'].values,self.start['zero'].values,np.log(self.start['theta']))))\n",
    "            ll_old = 2 * ll_new \n",
    "            \n",
    "            while np.absolute((ll_old - ll_new)/ll_old) > self.reltol :\n",
    "                ll_old = ll_new\n",
    "                model_count = sm.GLM(endog = self.Y, exog = self.X, family = \\\n",
    "                                sm.families.NegativeBinomial(alpha = 1/self.start['theta']),method = 'newton',\\\n",
    "                                  offset = self.offsetx , freq_weights = self.weights*(1-probi) \\\n",
    "                                      ).fit(start_params = self.start['count'])\n",
    "                model_zero = sm.GLM(probi, exog = self.Z, family=sm.families.Binomial(link = self.linkobj.linkclass),\\\n",
    "                        offset = self.offsetz, freq_weights = self.weights, \\\n",
    "                        start_params = self.start['zero']).fit()\n",
    "                \n",
    "                mui = model_count.predict() \n",
    "                theta = model_count.scale\n",
    "                \n",
    "                probi = model_zero.predict()\n",
    "                probi = probi/(probi + (1-probi)*st.nbinom.pmf(0,*self.convert_params(theta = theta, mu = mui)))\n",
    "                \n",
    "                probi[self.Y1] = 0\n",
    "                self.start = {'zero':model_zero.params, 'count':model_count.params, 'theta':theta}\n",
    "                \n",
    "                ll_new = self.loglikfun(np.hstack((self.start['count'].values,\\\n",
    "                                self.start['zero'].values,np.log(self.start['theta']))))\n",
    "\n",
    "        return self.start\n",
    "    \n",
    "     \n",
    "    def fit(self, method = 'BFGS', EM = True, start = None, reltol = None,\\\n",
    "            options = {'disp': False, 'maxiter': 10000}, factr = 1.0):\n",
    "        self.set_tolerance(factr, reltol)\n",
    "        self.optim_options = options\n",
    "        self.method = method\n",
    "        self.EM = EM\n",
    "        self.set_start(start)\n",
    "        \n",
    "        \n",
    "        ## ML Estimation\n",
    "        if (self.dist is 'negbin'):\n",
    "            x0 = np.hstack((self.start['count'].values,self.start['zero'].values,\\\n",
    "                                         np.log(self.start['theta'])))\n",
    "        else:\n",
    "            x0 = np.hstack((self.start['count'].values,self.start['zero'].values))\n",
    "\n",
    "        fitResult = sp.optimize.minimize(self.loglikfun, args=(-1.0,), x0 = x0, \\\n",
    "                                        method=self.method, jac=self.gradfun, options=self.optim_options)\n",
    "        \n",
    "        ## coefficients and covariances\n",
    "        coefc = pd.Series(data = fitResult.x[0:self.kx], index = self.X.columns.values)\n",
    "        coefz = pd.Series(data = fitResult.x[self.kx:self.kx+self.kz], index = self.Z.columns.values)\n",
    "\n",
    "        if self.method == 'L-BFGS-B':\n",
    "            vc_data = fitResult.hess_inv.todense()\n",
    "        elif self.method == 'BFGS':\n",
    "            vc_data = fitResult.hess_inv\n",
    "        else:\n",
    "            warnings.warn('Not tested for methods other than BFGS and L-BFGS-B.')\n",
    "            \n",
    "        vc = pd.DataFrame(data = vc_data[np.arange(self.kx+self.kz)[:,None],np.arange(self.kx+self.kz)], \\\n",
    "                      index = np.append(self.X.columns.values, self.Z.columns.values),\\\n",
    "                 columns = np.append(self.X.columns.values, self.Z.columns.values))\n",
    "        if self.dist == 'negbin':\n",
    "            ntheta = self.kx + self.kz\n",
    "            theta = np.exp(fitResult.x[ntheta])\n",
    "            SE_logtheta = np.sqrt(np.diagonal(vc_data)[ntheta])\n",
    "        else:\n",
    "            theta = None\n",
    "            SE_logtheta = None\n",
    "    \n",
    "        ## fitted and residuals\n",
    "        mu = np.exp(np.dot(self.X,coefc)+self.offsetx)\n",
    "        phi = self.linkobj.link_inv(np.dot(self.Z,coefz)+self.offsetz)\n",
    "        Yhat = (1-phi) * mu\n",
    "        res = np.sqrt(self.weights) * (self.Y - Yhat)\n",
    "\n",
    "        ## effective observations\n",
    "        nobs = np.sum(self.weights > 0)\n",
    "        \n",
    "        Result = ZeroInflatedResults(self.call, self.formula, self.terms, self.kx, self.kz, \\\n",
    "                                     self.dist, self.link, self.linkobj, self.optim_options, self.method, self.start,\\\n",
    "                                     self.reltol, self.weights, self.offsetx, self.offsetz,\\\n",
    "                                     fitResult, coefc, coefz, theta, SE_logtheta, nobs, res, Yhat, vc, self.endog,\\\n",
    "                                    self.X, self.Z)\n",
    "        return Result\n",
    "\n",
    "        \n",
    "        \n",
    "    def set_start(self, start):\n",
    "        if start is not None:\n",
    "            valid = True\n",
    "            if ('count' in start) is False:\n",
    "                valid = False\n",
    "                warnings.warn(\"invalid starting values, count model coefficients not specified\")\n",
    "                start['count'] = pd.Series(np.repeat(0,kx), index = X.columns.values)\n",
    "            if ('zero' in start) is False:\n",
    "                valid = False\n",
    "                warnings.warn(\"invalid starting values, zero model coefficients not specified\")\n",
    "                start['zero'] = pd.Series(np.repeat(0,kz), index = Z.columns.values)\n",
    "            if len(start['count']) != kx:\n",
    "                valid = False\n",
    "                warnings.warn(\"invalid starting values, wrong number of count model coefficients\")\n",
    "            if len(start['zero']) != kz:\n",
    "                valid = False\n",
    "                warnings.warn(\"invalid starting values, wrong number of zero model coefficients\")\n",
    "            if dist is 'negbin':\n",
    "                if ('theta' in start) is False:\n",
    "                    start['theta'] = 1.0\n",
    "                start = {'zero':start['zero'], 'count':start['count'], 'theta' : (start['theta'][0]).astype(float)}\n",
    "            else:\n",
    "                start = {'zero':start['zero'], 'count':start['count']}    \n",
    "        \n",
    "            if valid is False:\n",
    "                start = None\n",
    "\n",
    "        if start is None:\n",
    "            self.EM_estimate()\n",
    "        else:\n",
    "            self.start = start\n",
    "        \n",
    "     \n",
    "    def set_tolerance(self, factr=1.0, reltol = FLOAT_EPS**(1/1.6)):\n",
    "        if factr < 1.0:\n",
    "            warnings.warn('Minimum value of factr is 1.0.')\n",
    "            factr = 1.0\n",
    "        if reltol is None:\n",
    "            self.reltol = factr*((np.finfo(float).eps)**(1/1.6))\n",
    "            \n",
    "    @staticmethod    \n",
    "    def formula_processing(formula_str, data, missing='none'):\n",
    "        # ToDo: Add 'missing' operations on df\n",
    "        X_formula,Z_formula = formula_str.split(\"|\")\n",
    "        Z_formula = X_formula.split(\"~\")[0]+\" ~ \"+ Z_formula\n",
    "        y, X = patsy.dmatrices(X_formula, data, return_type='dataframe')\n",
    "        Z = patsy.dmatrices(Z_formula, data, return_type='dataframe')[1]\n",
    "        \n",
    "        Y = np.squeeze(y)\n",
    "        ## sanity checks\n",
    "        if len(Y) < 1:\n",
    "            sys.exit(\"empty model\")\n",
    "        if np.all(Y > 0):\n",
    "            sys.exit(\"invalid dependent variable, minimum count is not zero\")  \n",
    "        if np.array_equal(np.asarray(Y), (np.round(Y + 0.001)).astype(int)) is False:\n",
    "            sys.exit(\"invalid dependent variable, non-integer values\")\n",
    "        Y = (np.round(y + 0.001)).astype(int)\n",
    "        if np.any(Y < 0):\n",
    "            sys.exit(\"invalid dependent variable, negative counts\")\n",
    "            \n",
    "        return y,X,Z\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_params(mu, theta):\n",
    "        \"\"\"\n",
    "        Convert mean/dispersion parameterization of a negative binomial to the ones scipy supports\n",
    "\n",
    "        \"\"\"\n",
    "        n = theta\n",
    "        p = theta/(theta+mu)\n",
    "        return n, p\n",
    "            \n",
    "    \n",
    "    @staticmethod\n",
    "    def _link_processing(link):\n",
    "        ## binary link processing\n",
    "        linkstr = link\n",
    "        linkList = ['logit','probit','cauchit','cloglog','log']\n",
    "        if linkstr not in linkList:\n",
    "            warnings.warn(linkstr +\" link not valid. Available links are: \" + str(linkList))\n",
    "            linkstr = 'logit'\n",
    "        return(linkstr)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _LinkClass_processing(linkstr):\n",
    "        Link = {\n",
    "            'logit': Logit(),\n",
    "            'probit': Probit(),\n",
    "            'cloglog': CLogLog(),\n",
    "            'cauchit': Cauchit(),\n",
    "            'log': Log(),\n",
    "        }\n",
    "        return Link.get(linkstr, Logit())\n",
    "    \n",
    "    @staticmethod\n",
    "    def _dist_processing(dist):\n",
    "        if dist not in ['poisson','negbin','geom']:\n",
    "            sys.exit(dist+\" method not yet implemented\")\n",
    "        return dist\n",
    "    \n",
    "\n",
    "class ZeroInflatedResults(object):\n",
    "    def __init__(self, call, formula, terms, kx, kz, dist, link, linkobj, options, method, start, reltol, \\\n",
    "                 weights, offsetx, offsetz, fitResult, coefc, coefz, theta, SE_logtheta,\\\n",
    "                nobs, res, Yhat, vc, y, X, Z):\n",
    "        \n",
    "        # Need to change final results objects names to standard names used in python\n",
    "        self.call = call\n",
    "        self.formula = formula\n",
    "        self.terms = terms\n",
    "        self.kx = kx\n",
    "        self.kz = kz\n",
    "        self.n = self.nobs = nobs\n",
    "        \n",
    "        # fit paramters\n",
    "        self.dist = dist\n",
    "        self.linkstr = link\n",
    "        self.link = linkobj.link\n",
    "        self.linkinv = linkobj.link_inv\n",
    "        self.optim_options = options\n",
    "        self.method = method\n",
    "        self.start = start\n",
    "        self.reltol = reltol\n",
    "                \n",
    "        self.weights = weights \n",
    "        self.offsetx = offsetx\n",
    "        self.offsetz = offsetz\n",
    "        self.linkobj = linkobj\n",
    "        \n",
    "        # Optimization Results\n",
    "        self.fit = fitResult\n",
    "        self.loglik = fitResult.fun*(-1)    # log-likelihood\n",
    "        self.converged = fitResult.success\n",
    "        self.iters = fitResult.nit;          # number of iterations for convergence\n",
    "        self.coefficients = {'count':coefc ,'zero': coefz}\n",
    "        self.theta = theta if (dist is 'negbin') else None\n",
    "        self.SE_logtheta = SE_logtheta\n",
    "        self.df_null = nobs - 2\n",
    "        self.df_resid = nobs - (kx + kz + (dist == \"negbin\"))\n",
    "        self.df_model = (kx + kz + (dist == \"negbin\"))\n",
    "        self.residuals = res \n",
    "        self.fitted_values = Yhat\n",
    "        self.vcov = vc\n",
    "        self.y = y\n",
    "        self._X = X\n",
    "        self._Z = Z\n",
    "        \n",
    "        self.deviance = 0\n",
    "        self.pearson_chi2 = 0\n",
    "        self.cov_type = None\n",
    "        self.use_t = False\n",
    "        \n",
    "    def __repr__(self):\n",
    "        display_string = \"Call:\\n    \"+self.call\n",
    "        display_string += \"\\n\\nformula:\\n    \"+self.formula\n",
    "        #display_string += f\"\\nterms:\\n    Y: {self.terms['Y']}\\n    X: {self.terms['X']}\\n    Z: {self.terms['Z']}\"\n",
    "        display_string += \"\\ndist: \"+self.dist\n",
    "        display_string += \"\\nlink: \"+self.linkstr\n",
    "        display_string += \"\\nlinkobj:\"+ self.linkobj.__repr__()\n",
    "        display_string += f\"\\nMessage: {self.fit.message}\"\n",
    "        display_string += f\"\\nResult: \\n    Count:\\n\"\n",
    "        display_string += f\"{self.coefficients['count']}\\n    Zero:\\n{self.coefficients['zero']}\"\n",
    "        display_string += f\"\\n    theta: {self.theta:0.12f}\" if self.dist is 'negbin' else \" \"\n",
    "        display_string += f\"\\ndf_null: {self.df_null} \\ndf_resid: {self.df_resid}\"\n",
    "        return display_string\n",
    "    \n",
    "    # Merged function definitions from zipModel start here:\n",
    "    -\n",
    "        #display(HTML(pd.DataFrame(z_df).to_html))\n",
    "        #print(\"\\n\")\n",
    "        \n",
    "        # for line in [self.terms['Z'], np.round(self.coefficients['zero'],4)]:\n",
    "        #     print(('{:>12}' * p_zero).format(*line))        \n",
    "    \n",
    "    # return variance-covariance matrix for calculation purposes\n",
    "    def covar(self):\n",
    "        return(self.vcov)\n",
    "    \n",
    "    # formatted version of the variance-covariance matrix\n",
    "    #def printCov(self):\n",
    "    #    pd.set_option('display.float_format', '{:.3E}'.format)\n",
    "    #    cov_mat = pd.DataFrame(self.vcov)\n",
    "    #    display(HTML(cov_mat.to_html(index=False)))\n",
    "        \n",
    "    def summary(self):\n",
    "        RESIDUAL_OUTPUT = \"Pearson residuals:\"\n",
    "        MODEL1_HEADER = f\"Count model cefficients ({self.dist} log link): \"\n",
    "        MODEL2_HEADER = f\"Zero-inflation model coefficients (binomial with {self.linkstr} link): \"\n",
    "\n",
    "        \n",
    "        ## chunk 1: output call, formula\n",
    "        print(\"\\nCall:\\n\" + self.call +'\\n')\n",
    "        \n",
    "        \n",
    "        ## chunk 2: output pearson residuals -- residuals function still needs to be implemented\n",
    "        # object$residuals = residuals(object, type = \"pearson\")\n",
    "        resid_summ = np.round(st.mstats.mquantiles(self.residuals, prob = [0, 0.25, 0.5, 0.75, 1.0]), 5)\n",
    "        resid_str  = ['Min', '1Q', 'Median', '3Q','Max'];\n",
    "        print(RESIDUAL_OUTPUT)\n",
    "        for line in [resid_str, resid_summ]:\n",
    "            print(('{:>10}' * len(resid_summ)).format(*line))\n",
    "        #print(\"\\n\")\n",
    "\n",
    "        # compute standard error for all coefficients (both models)\n",
    "        se = np.sqrt(np.diagonal(self.vcov)) \n",
    "\n",
    "        # compute z statistics for both models\n",
    "        z_count = np.array(self.coefficients['count']) / se[0:self.kx]\n",
    "        z_zip = np.array(self.coefficients['zero']) / se[self.kx:self.kx+self.kz]\n",
    "\n",
    "        # compute p-values\n",
    "        pval_count = 2 * st.norm.cdf(-np.abs(z_count));\n",
    "        pval_zip = 2 * st.norm.cdf(-np.abs(z_zip));\n",
    "        \n",
    "        # format p-values for output\n",
    "        pc_format = [0] * len(pval_count)\n",
    "        pz_format = [0] * len(pval_zip)\n",
    "\n",
    "        for i in np.arange(len(pval_count)):\n",
    "            if pval_count[i] < 2e-16:\n",
    "                pc_format[i] = str(\"<2e-16\")\n",
    "            else:\n",
    "                pc_format[i] = str(\"{:.4e}\".format(Decimal(pval_count[i])))\n",
    "\n",
    "        for i in np.arange(len(pval_zip)):\n",
    "            if pval_zip[i] < 2e-16:\n",
    "                pz_format[i] = str(\"<2e-16\")\n",
    "            else:\n",
    "                pz_format[i] = str(\"{:.4e}\".format(Decimal(pval_zip[i])))\n",
    "                \n",
    "        ## chunk 3: output count model coefficients\n",
    "        print('\\n')\n",
    "        print(MODEL1_HEADER)\n",
    "        coeff_label = ['', 'Estimate', 'Std. Error', 'z value', 'Pr(>|z|)'];\n",
    "        data_count = [coeff_label] + list(zip(self.terms['X'], np.round(self.coefficients['count'],4), \\\n",
    "                                        np.round(se[0:self.kx], 4), np.round(z_count, 3), pc_format))\n",
    "        coeff_maxlen = np.max([len(x) for x in self.terms['X']])\n",
    "        SPACE = 20 if coeff_maxlen > 10 else 12\n",
    "        \n",
    "        for i, d in enumerate(data_count): \n",
    "            line = '|'.join(str(x).rjust(SPACE if x==d[0] else 10) for x in d)\n",
    "            print(line)\n",
    "            if i == 0:\n",
    "                print('-' * len(line))\n",
    "\n",
    "        print('\\n')\n",
    "                    \n",
    "        ## chunk 4: output zero-inflation model coefficients\n",
    "        print(MODEL2_HEADER)\n",
    "        data_zero = [coeff_label] + list(zip(self.terms['Z'], np.round(self.coefficients['zero'],4), \\\n",
    "                                        np.round(se[self.kx:], 4), np.round(z_zip, 3), pz_format))\n",
    "        coeff_maxlen = np.max([len(x) for x in self.terms['Z']])\n",
    "        SPACE = 20 if coeff_maxlen > 10 else 12  \n",
    "        for i, d in enumerate(data_zero):\n",
    "            line = '|'.join(str(x).rjust(SPACE if x==d[0] else 10) for x in d)\n",
    "            print(line)\n",
    "            if i == 0:\n",
    "                print('-' * len(line))\n",
    "        #print('\\n')\n",
    "        print('---')\n",
    "        \n",
    "        ## chunk 5: Number of iterations, log-likelihood\n",
    "        print(f\"Number of iterations in {self.method} optimization: \" + str(self.iters));\n",
    "        if self.converged is False:\n",
    "            print(\"Failed to converge.\")\n",
    "        print(\"Log-likelihood: \" + str(self.loglik))        \n",
    "        \n",
    "        \n",
    "        # m: fitted zip model\n",
    "        # pred_type: 'response', 'count', 'zero', or 'prob'\n",
    "        # newdata_X: design matrix for count model\n",
    "        # newdata_Z: design matrix for zero model\n",
    "        def predict(m, pred_type, newdata_X = None, newdata_Z = None): \n",
    "\n",
    "            if pred_type not in [\"response\", \"count\", \"zero\", \"prob\"]:\n",
    "                print(\"Error: Prediction of type \\'\" + pred_type + \"\\' is not supported\")\n",
    "                return\n",
    "\n",
    "            if newdata_X is None and newdata_Z is None:\n",
    "                rval = m.fitted_values\n",
    "                if pred_type != 'response':\n",
    "                    X = m._X                   # training matrix for count model with intercept in first column\n",
    "                    Z = m._Z                   # training matrix for zero model with intercept in first column\n",
    "\n",
    "                    ## offset \n",
    "                    # offsetx = 0.0\n",
    "                    #offsetx = np.repeat(0.0,self.n)\n",
    "                    offsetx = np.repeat(0.0, X.shape[0])\n",
    "\n",
    "                    # offsetz = 0.0\n",
    "                    # offsetz = np.repeat(0.0,self.n)\n",
    "                    offsetz = np.repeat(0.0, Z.shape[0])\n",
    "\n",
    "                    ## count mean\n",
    "                    # mu = np.exp(np.dot(X,m.coefficients['count']) + offsetx)\n",
    "                    ## binary mean\n",
    "                    # phi = self.linkobj.link_inv(np.dot(Z, m.coefficients['zero']) + offsetz)\n",
    "                    # Not sure if it's what's needed here but consider code commented above. was compatible\n",
    "                    # with offsetx and offsetz in earlier functions.\n",
    "\n",
    "                    mu = np.exp(np.matmul(X, m.coefficients['count']) + offsetx)\n",
    "                    phi = m.linkinv(np.matmul(Z, m.coefficients['zero']) + offsetz)\n",
    "            elif newdata_X is None or newdata_Z is None:\n",
    "                print(\"Design Matrix for both count model and zero-inflated model must be specified\")\n",
    "                return\n",
    "            else:\n",
    "                X = newdata_X\n",
    "                Z = newdata_Z\n",
    "                offsetx = np.repeat(0.0, X.shape[0])\n",
    "                offsetz = np.repeat(0.0, Z.shape[0])\n",
    "                mu = np.exp(np.matmul(X, m.coefficients['count']) + offsetx)\n",
    "                phi = m.linkinv(np.matmul(Z, m.coefficients['zero']) + offsetz)\n",
    "                rval = (1 - phi) * mu\n",
    "\n",
    "\n",
    "            # predicted means for count/zero component\n",
    "            if pred_type == 'count':\n",
    "                rval = mu\n",
    "            if pred_type == 'zero':\n",
    "                rval = phi\n",
    "\n",
    "            if pred_type == 'prob':\n",
    "                if(y is not none):\n",
    "                    y = np.squeeze(m.y)\n",
    "                else:\n",
    "                    print(\"Predicted Probabilities require non-null values for y\")\n",
    "\n",
    "                yUnique = np.arange(0, np.max(m0.y) + 1)\n",
    "                nUnique = len(yUnique)\n",
    "                rval = np.zeros(shape = (len(rval), nUnique))\n",
    "\n",
    "                if m.dist == 'poisson':\n",
    "                    rval[:,0] = phi + (1 - phi) * np.exp(-mu) # first column of r_val\n",
    "                    for i in np.arange(1,nUnique):\n",
    "                        # can this be vectorized instead of for loop?\n",
    "                        rval[:,i] = (1 - phi) * poisson.pmf(yUnique[i], mu)\n",
    "                elif m.dist == 'negbin':\n",
    "                    theta = self.theta\n",
    "                    rval[:,0] = phi + (1 - phi) * nbinom.pmf(yUnique[i],*self.convert_params(theta = theta, mu = mu))\n",
    "                    for i in np.arange(1,nUnique):\n",
    "                        # can this be vectorized instead of for loop?\n",
    "                        # should size be 1 in negbin?\n",
    "                        rval[:,i] = (1 - phi) * nbinom.pmf(yUnique[i],*self.convert_params(theta = 1, mu = mu))\n",
    "                elif m.dist == 'geom':\n",
    "                    rval[:,0] = phi + (1 - phi) * nbinom.pmf(yUnique[i],*self.convert_params(theta = 1, mu = mu))\n",
    "                    for i in np.arange(1,nUnique):\n",
    "                        # can this be vectorized instead of for loop?\n",
    "                        rval[:,i] = (1 - phi) * nbinom.pmf(yUnique[i],*self.convert_params(theta = 1, mu = mu))\n",
    "                else: \n",
    "                    print(\"unsupported distribution\")\n",
    "\n",
    "            return(rval)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "nbpresent": {
     "id": "c8e4b35b-5791-4336-b5ce-16b442c9a499"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:251: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "ZeroInflated(formula_str='ofp ~ hosp + health + numchron + gender + school + privins | health', data=df, dist='poisson', offsetx=None, offsetz=None, link='logit', weights=None, missing='none')\n",
      "\n",
      "Count model cefficients (poisson log link): \n",
      "  Intercept health[T.excellent] health[T.poor] gender[T.male] privins[T.yes]  \\\n",
      "    1.39367            -0.30775        0.25420       -0.06486        0.08544   \n",
      "\n",
      "      hosp numchron   school  \n",
      "   0.15913  0.10328  0.01959  \n",
      "\n",
      "\n",
      "Zero-inflation model coefficients (binomial with logit link): \n",
      "  Intercept health[T.excellent] health[T.poor]\n",
      "   -1.73364             0.47491       -0.39916\n"
     ]
    }
   ],
   "source": [
    "### Lines below will not go inside the function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core import datetools\n",
    "\n",
    "df = pd.read_csv('DebTrivedi.csv',index_col = [0])\n",
    "sel = np.array([1, 6, 7, 8, 13, 15, 18])-1\n",
    "df = df.iloc[:,sel]\n",
    "\n",
    "formula_str = 'ofp ~ hosp + health + numchron + gender + school + privins | health'\n",
    "# ZeroInflated(formula_str,df).fit().printModel()\n",
    "# ZeroInflated(formula_str,df).fit().summary()\n",
    "\n",
    "\n",
    "\n",
    "ZeroInflated(formula_str, df).fit(EM=False).printModel()\n",
    "#preds = pred(m0, \"count\", m0._X, m0._Z)#\n",
    "#print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b7942bdd-d9fd-4a3c-b4b1-9aa4db764b13"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pred(m, pred_type, newdata_X = None, newdata_Z = None): \n",
    "    \n",
    "        \n",
    "    if pred_type not in [\"response\", \"count\", \"zero\", \"prob\"]:\n",
    "        print(\"Error: Prediction of type \\'\" + pred_type + \"\\' is not supported\")\n",
    "        return\n",
    "        \n",
    "    if newdata_X is None and newdata_Z is None:\n",
    "        rval = m.fitted_values\n",
    "        if pred_type != 'response':\n",
    "            X = m._X                   # training matrix for count model with intercept in first column\n",
    "            Z = m._Z                   # training matrix for zero model with intercept in first column\n",
    "            \n",
    "            ## offset \n",
    "            offsetx = 0.0\n",
    "            # offsetx = np.repeat(0.0,self.n)\n",
    "            offsetx = np.repeat(0.0, X.shape[0])\n",
    "\n",
    "            offsetz = 0.0\n",
    "            # offsetz = np.repeat(0.0,self.n)\n",
    "            offsetz = np.repeat(0.0, Z.shape[0])\n",
    "            \n",
    "            ## count mean\n",
    "            # mu = np.exp(np.dot(X,m.coefficients['count']) + offsetx)\n",
    "            ## binary mean\n",
    "            # phi = self.linkobj.link_inv(np.dot(Z, m.coefficients['zero']) + offsetz)\n",
    "            # Not sure if it's what's needed here but consider code commented above. was compatible\n",
    "            # with offsetx and offsetz in earlier functions.\n",
    "            \n",
    "            mu = np.exp(np.matmul(X, m.coefficients['count']) + offsetx)\n",
    "            phi = m.linkinv(np.matmul(Z, m.coefficients['zero']) + offsetz)\n",
    "    elif newdata_X is None or newdata_Z is None:\n",
    "        print(\"Design Matrix for both count model and zero-inflated model must be specified\")\n",
    "        return\n",
    "    else:\n",
    "        X = newdata_X\n",
    "        Z = newdata_Z\n",
    "        offsetx = np.repeat(0.0, X.shape[0])\n",
    "        offsetz = np.repeat(0.0, Z.shape[0])\n",
    "        mu = np.exp(np.matmul(X, m.coefficients['count']) + offsetx)\n",
    "        phi = m.linkinv(np.matmul(Z, m.coefficients['zero']) + offsetz)\n",
    "        rval = (1 - phi) * mu\n",
    "        \n",
    "    \n",
    "    # predicted means for count/zero component\n",
    "    if pred_type == 'count':\n",
    "        print(\"type is count\")\n",
    "        rval = mu\n",
    "    if pred_type == 'zero':\n",
    "        print(\"type is zero\")\n",
    "        rval = phi\n",
    "        \n",
    "    if pred_type == 'prob':\n",
    "        if(y is not none):\n",
    "            y = np.squeeze(m.y)\n",
    "        else:\n",
    "            print(\"Predicted Probabilities require non-null values for y\")\n",
    "        \n",
    "        yUnique = np.arange(0, np.max(m0.y) + 1)\n",
    "        nUnique = len(yUnique)\n",
    "        rval = np.zeros(shape = (len(rval), nUnique))\n",
    "        \n",
    "        if m.dist == 'poisson':\n",
    "            rval[:,0] = phi + (1 - phi) * np.exp(-mu) # first column of r_val\n",
    "            for i in np.arange(1,nUnique):\n",
    "                # can this be vectorized instead of for loop?\n",
    "                rval[:,i] = (1 - phi) * poisson.pmf(yUnique[i], mu)\n",
    "        elif m.dist == 'negbin':\n",
    "            theta = self.theta\n",
    "            rval[:,0] = phi + (1 - phi) * nbinom.pmf(yUnique[i],*self.convert_params(theta = theta, mu = mu))\n",
    "            for i in np.arange(1,nUnique):\n",
    "                # can this be vectorized instead of for loop?\n",
    "                # should size be 1 in negbin?\n",
    "                rval[:,i] = (1 - phi) * nbinom.pmf(yUnique[i],*self.convert_params(theta = 1, mu = mu))\n",
    "        elif m.dist == 'geom':\n",
    "            rval[:,0] = phi + (1 - phi) * nbinom.pmf(yUnique[i],*self.convert_params(theta = 1, mu = mu))\n",
    "            for i in np.arange(1,nUnique):\n",
    "                # can this be vectorized instead of for loop?\n",
    "                rval[:,i] = (1 - phi) * nbinom.pmf(yUnique[i],*self.convert_params(theta = 1, mu = mu))\n",
    "        else: \n",
    "            print(\"unsupported distribution\")\n",
    "        \n",
    "    return(rval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7b24b379-f281-4c32-a8b4-7e37b3b0b8dc"
    }
   },
   "source": [
    "`R Results(Poisson) for vcov:`\n",
    "   \n",
    "`(Intercept)      healthpoor healthexcellent      gendermale      privinsyes            hosp `\n",
    "   \n",
    "`6.005633e-04    3.142243e-04    9.877262e-04    1.718968e-04    2.996214e-04    3.671290e-05 `\n",
    "\n",
    "`numchron          school     (Intercept)      healthpoor healthexcellent `\n",
    "\n",
    "`2.243342e-05    3.551701e-06    2.312595e-03    2.147746e-02    2.114617e-02`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "73047380-dccb-4cfc-8162-572ed6fbb1a4"
    }
   },
   "outputs": [],
   "source": [
    "X_formula = 'ofp ~ hosp + health + numchron + gender + school + privins'\n",
    "y, X = patsy.dmatrices(X_formula, df, return_type='dataframe')\n",
    "Z_formula = 'ofp ~ health'\n",
    "Z = patsy.dmatrices(Z_formula, df, return_type='dataframe')[1]\n",
    "model_count = sm.GLM(endog = y, exog = X, family = sm.families.Poisson()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "nbpresent": {
     "id": "7b3d738f-252b-4f2c-9937-5f1240c05cc5"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29999999999999999"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import poisson\n",
    "from scipy.stats import nbinom\n",
    "\n",
    "nbinom.pmf(0, 1, 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbpresent": {
     "id": "f3d94c83-620f-45af-8d2d-745ec88fec11"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>ofp</td>       <th>  No. Observations:  </th>  <td>  4406</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  4398</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>     7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -17972.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Thu, 05 Apr 2018</td> <th>  Deviance:          </th> <td>  23168.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>22:38:22</td>     <th>  Pearson chi2:      </th> <td>2.95e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>5</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>           <td>    1.0289</td> <td>    0.024</td> <td>   43.257</td> <td> 0.000</td> <td>    0.982</td> <td>    1.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>health[T.excellent]</th> <td>   -0.3620</td> <td>    0.030</td> <td>  -11.945</td> <td> 0.000</td> <td>   -0.421</td> <td>   -0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>health[T.poor]</th>      <td>    0.2483</td> <td>    0.018</td> <td>   13.915</td> <td> 0.000</td> <td>    0.213</td> <td>    0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender[T.male]</th>      <td>   -0.1123</td> <td>    0.013</td> <td>   -8.677</td> <td> 0.000</td> <td>   -0.138</td> <td>   -0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>privins[T.yes]</th>      <td>    0.2017</td> <td>    0.017</td> <td>   11.962</td> <td> 0.000</td> <td>    0.169</td> <td>    0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hosp</th>                <td>    0.1648</td> <td>    0.006</td> <td>   27.478</td> <td> 0.000</td> <td>    0.153</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numchron</th>            <td>    0.1466</td> <td>    0.005</td> <td>   32.019</td> <td> 0.000</td> <td>    0.138</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>school</th>              <td>    0.0261</td> <td>    0.002</td> <td>   14.182</td> <td> 0.000</td> <td>    0.023</td> <td>    0.030</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                    ofp   No. Observations:                 4406\n",
       "Model:                            GLM   Df Residuals:                     4398\n",
       "Model Family:                 Poisson   Df Model:                            7\n",
       "Link Function:                    log   Scale:                             1.0\n",
       "Method:                          IRLS   Log-Likelihood:                -17972.\n",
       "Date:                Thu, 05 Apr 2018   Deviance:                       23168.\n",
       "Time:                        22:38:22   Pearson chi2:                 2.95e+04\n",
       "No. Iterations:                     5                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Intercept               1.0289      0.024     43.257      0.000       0.982       1.075\n",
       "health[T.excellent]    -0.3620      0.030    -11.945      0.000      -0.421      -0.303\n",
       "health[T.poor]          0.2483      0.018     13.915      0.000       0.213       0.283\n",
       "gender[T.male]         -0.1123      0.013     -8.677      0.000      -0.138      -0.087\n",
       "privins[T.yes]          0.2017      0.017     11.962      0.000       0.169       0.235\n",
       "hosp                    0.1648      0.006     27.478      0.000       0.153       0.177\n",
       "numchron                0.1466      0.005     32.019      0.000       0.138       0.156\n",
       "school                  0.0261      0.002     14.182      0.000       0.023       0.030\n",
       "=======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_count.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "d46eead9-6a06-40ac-b346-0f3a73e65317"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>               <td>GLM</td>            <td>AIC:</td>       <td>35959.2256</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>Link Function:</td>           <td>log</td>            <td>BIC:</td>       <td>-13734.5914</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>        <td>ofp</td>       <td>Log-Likelihood:</td>   <td>-17972.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2018-04-05 22:40</td>    <td>LL-Null:</td>       <td>-19859.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>4406</td>          <td>Deviance:</td>      <td>23168.</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>7</td>         <td>Pearson chi2:</td>   <td>2.95e+04</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>4398</td>           <td>Scale:</td>        <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>Method:</td>             <td>IRLS</td>              <td></td>              <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>            <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>           <td>1.0289</td>   <td>0.0238</td>   <td>43.2575</td> <td>0.0000</td> <td>0.9823</td>  <td>1.0755</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>health[T.excellent]</th> <td>-0.3620</td>  <td>0.0303</td>  <td>-11.9452</td> <td>0.0000</td> <td>-0.4214</td> <td>-0.3026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>health[T.poor]</th>      <td>0.2483</td>   <td>0.0178</td>   <td>13.9149</td> <td>0.0000</td> <td>0.2133</td>  <td>0.2833</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender[T.male]</th>      <td>-0.1123</td>  <td>0.0129</td>   <td>-8.6765</td> <td>0.0000</td> <td>-0.1377</td> <td>-0.0869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>privins[T.yes]</th>      <td>0.2017</td>   <td>0.0169</td>   <td>11.9624</td> <td>0.0000</td> <td>0.1686</td>  <td>0.2347</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hosp</th>                <td>0.1648</td>   <td>0.0060</td>   <td>27.4782</td> <td>0.0000</td> <td>0.1530</td>  <td>0.1766</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numchron</th>            <td>0.1466</td>   <td>0.0046</td>   <td>32.0194</td> <td>0.0000</td> <td>0.1377</td>  <td>0.1556</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>school</th>              <td>0.0261</td>   <td>0.0018</td>   <td>14.1824</td> <td>0.0000</td> <td>0.0225</td>  <td>0.0298</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                 Results: Generalized linear model\n",
       "====================================================================\n",
       "Model:                GLM               AIC:             35959.2256 \n",
       "Link Function:        log               BIC:             -13734.5914\n",
       "Dependent Variable:   ofp               Log-Likelihood:  -17972.    \n",
       "Date:                 2018-04-05 22:40  LL-Null:         -19859.    \n",
       "No. Observations:     4406              Deviance:        23168.     \n",
       "Df Model:             7                 Pearson chi2:    2.95e+04   \n",
       "Df Residuals:         4398              Scale:           1.0000     \n",
       "Method:               IRLS                                          \n",
       "--------------------------------------------------------------------\n",
       "                     Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
       "--------------------------------------------------------------------\n",
       "Intercept            1.0289   0.0238  43.2575 0.0000  0.9823  1.0755\n",
       "health[T.excellent] -0.3620   0.0303 -11.9452 0.0000 -0.4214 -0.3026\n",
       "health[T.poor]       0.2483   0.0178  13.9149 0.0000  0.2133  0.2833\n",
       "gender[T.male]      -0.1123   0.0129  -8.6765 0.0000 -0.1377 -0.0869\n",
       "privins[T.yes]       0.2017   0.0169  11.9624 0.0000  0.1686  0.2347\n",
       "hosp                 0.1648   0.0060  27.4782 0.0000  0.1530  0.1766\n",
       "numchron             0.1466   0.0046  32.0194 0.0000  0.1377  0.1556\n",
       "school               0.0261   0.0018  14.1824 0.0000  0.0225  0.0298\n",
       "====================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_count.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "2e164e1a-a5c7-495a-8bb0-a68ae2c4b647"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LikelihoodModelResults.wald_test_terms of <statsmodels.genmod.generalized_linear_model.GLMResults object at 0x11bc7a4a8>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Available in glm\n",
    "model_count.aic\n",
    "model_count.bic\n",
    "model_count.bse\n",
    "model_count.conf_int\n",
    "model_count.converged\n",
    "model_count.cov_kwds\n",
    "model_count.cov_params\n",
    "model_count.cov_type\n",
    "model_count.data_in_cache\n",
    "model_count.deviance\n",
    "model_count.df_model\n",
    "model_count.df_resid\n",
    "model_count.f_test\n",
    "model_count.family\n",
    "model_count.fit_history\n",
    "model_count.fittedvalues\n",
    "model_count.get_prediction\n",
    "model_count.initialize\n",
    "model_count.k_constant\n",
    "model_count.llf\n",
    "model_count.llnull\n",
    "model_count.load\n",
    "model_count.method\n",
    "model_count.mu\n",
    "model_count.nobs\n",
    "model_count.normalized_cov_params\n",
    "model_count.null\n",
    "model_count.null_deviance\n",
    "model_count.params\n",
    "model_count.pearson_chi2\n",
    "model_count.pinv_wexog\n",
    "model_count.plot_added_variable\n",
    "model_count.plot_ceres_residuals\n",
    "model_count.plot_partial_residuals\n",
    "model_count.predict\n",
    "model_count.pvalues\n",
    "model_count.remove_data\n",
    "model_count.resid_anscombe\n",
    "model_count.resid_deviance\n",
    "model_count.resid_pearson\n",
    "model_count.resid_response\n",
    "model_count.resid_working\n",
    "model_count.save\n",
    "model_count.scale\n",
    "model_count.summary\n",
    "model_count.summary2\n",
    "model_count.t_test\n",
    "model_count.tvalues\n",
    "model_count.use_t\n",
    "model_count.wald_test\n",
    "model_count.wald_test_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "04749a1e-8e1f-4ee0-9efe-bd70394261bb"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "434d5bb2-160e-41ab-ac95-0e25675d6665"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "84542eb7-073c-4835-b873-0a5bf0f39c04"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
